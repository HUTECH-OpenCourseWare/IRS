{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Cài đặt thư viện UnderTheSea để hỗ trợ tách từ trong tiếng Việt. Xem thêm các tính năng của thư viện tại: https://github.com/undertheseanlp/underthesea**"
      ],
      "metadata": {
        "id": "FOLoVLyECf0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlMwgYMaCdfL",
        "outputId": "e87bee29-d20a-4002-dc82-9815f44ff564"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-1.4.0-py3-none-any.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from underthesea) (4.64.1)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from underthesea) (1.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from underthesea) (3.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from underthesea) (6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from underthesea) (1.2.0)\n",
            "Collecting underthesea-core==0.0.5a2\n",
            "  Downloading underthesea_core-0.0.5_alpha.2-cp38-cp38-manylinux2010_x86_64.whl (591 kB)\n",
            "\u001b[K     |████████████████████████████████| 591 kB 23.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->underthesea) (2022.6.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-1.4.0 underthesea-core-0.0.5a2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import các thư viện cần thiết**"
      ],
      "metadata": {
        "id": "frDnmyWhCYzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-GENCU8JCBRx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "from underthesea import text_normalize\n",
        "from underthesea import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lấy dữ liệu các tài liệu/văn bản mẫu từ**: https://github.com/HUTECH-OpenCourseWare/IRS.git"
      ],
      "metadata": {
        "id": "kaA8lcrzE30I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HUTECH-OpenCourseWare/IRS.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE2iAON0E4JY",
        "outputId": "89dd9362-cfc1-4c00-eb03-618f016c3261"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IRS'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (271/271), done.\u001b[K\n",
            "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
            "remote: Total 271 (delta 0), reused 271 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (271/271), 441.48 KiB | 1.79 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiến hành thử nghiệm với danh sách các tài liệu/văn bản thuộc các chủ đề khác nhau**"
      ],
      "metadata": {
        "id": "C0uVp--7CkTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chọn danh sách các chủ đề của tài liệu/văn bản cho thử nghiệm\n",
        "topics = [\n",
        "    'the-thao',\n",
        "    'giao-duc',\n",
        "    'khoa-hoc'\n",
        "]\n",
        "\n",
        "# Tạo một tập dữ liệu thử nghiệm gồm các tài liệu/văn bản thuộc về 2-3 chủ đề\n",
        "# Cấu trúc dữ liệu dạng list - lưu thông tin danh sách các tài liệu/văn bản thuộc chủ đề khác nhau\n",
        "# Mỗi tài liệu/văn bản sẽ tổ chức dạng 1 tuple với: (topic, nội_dung_văn_bản, danh_sách_token)\n",
        "D = []"
      ],
      "metadata": {
        "id": "6iZkFejfC4eq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiến hành viết một số hàm hỗ trợ cho việc đọc dữ liệu, xử lý và tách từ trong tiếng Việt.**"
      ],
      "metadata": {
        "id": "SqiSLgDqHKhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Viết hàm tiền xử lý và tách từ tiếng Việt\n",
        "def preprocess(doc):\n",
        "  # Tiến hành xử lý các lỗi từ/câu, dấu câu, v.v. trong tiếng Việt với hàm text_normalize\n",
        "  normalized_doc = text_normalize(doc)\n",
        "  # Tiến hành tách từ\n",
        "  tokens = word_tokenize(normalized_doc)\n",
        "  # Tiến hành kết hợp các từ ghép trong tiếng Việt bằng '_'\n",
        "  combined_tokens = [token.replace(' ', '_') for token in tokens]\n",
        "  return (normalized_doc, combined_tokens)\n",
        "\n",
        "# Viết hàm lấy danh sách các văn bản/tài liệu thuộc các chủ đề khác nhau\n",
        "def fetch_doc_by_topic(topic):\n",
        "  data_root_dir_path = '/content/IRS/data/vnexpress/{}'.format(topic)\n",
        "  docs = []\n",
        "  for file_name in os.listdir(data_root_dir_path):\n",
        "    file_path = os.path.join(data_root_dir_path, file_name)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "      lines = []\n",
        "      for line in f:\n",
        "        line = line.lower().strip()\n",
        "        lines.append(line)\n",
        "    doc = \" \".join(lines)\n",
        "    clean_doc = re.sub('\\W+',' ', doc)\n",
        "    (normalized_doc, tokens) = preprocess(clean_doc)\n",
        "    docs.append((topic, normalized_doc, tokens))\n",
        "  return docs"
      ],
      "metadata": {
        "id": "sKDirmg4HLjE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiến hành tạo tập dữ liệu thử nghiệm với các tài liệu/văn bản thuộc danh sách chủ đề [topics] đã lựa chọn bên trên**"
      ],
      "metadata": {
        "id": "XN2SlP6qHYKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cấu trúc dữ liệu dictionary để lưu thông tin chủ đề-tài liệu, nhằm hỗ trợ cho việc tìm kiếm nhanh\n",
        "topic_doc_idxes_dict = {}\n",
        "doc_idx_topic_dict = {}\n",
        "\n",
        "# Duyệt qua từng chủ đề\n",
        "doc_idx = 0\n",
        "for topic in topics:\n",
        "  current_topic_docs = fetch_doc_by_topic(topic)\n",
        "  topic_doc_idxes_dict[topic] = []\n",
        "  for (topic, normalized_doc, tokens) in current_topic_docs:\n",
        "    topic_doc_idxes_dict[topic].append(doc_idx)\n",
        "    doc_idx_topic_dict[doc_idx] = topic\n",
        "    doc_idx+=1\n",
        "  D += current_topic_docs\n",
        "\n",
        "doc_size = len(D)\n",
        "\n",
        "print('Hoàn tất, tổng số lượng tài liệu/văn bản đã lấy: [{}]'.format(doc_size))\n",
        "for topic in topic_doc_idxes_dict.keys():\n",
        "  print(' - Chủ đề [{}] có [{}] tài liệu/văn bản.'.format(topic, len(topic_doc_idxes_dict[topic])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTKEQar_Hjga",
        "outputId": "8cda0135-aac7-4097-eebd-27be9f9f34e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hoàn tất, tổng số lượng tài liệu/văn bản đã lấy: [109]\n",
            " - Chủ đề [the-thao] có [39] tài liệu/văn bản.\n",
            " - Chủ đề [giao-duc] có [35] tài liệu/văn bản.\n",
            " - Chủ đề [khoa-hoc] có [35] tài liệu/văn bản.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiến hành biến đổi các tài liệu/văn bản trong tập (D) về dạng các TF-IDF vectors - trong bài thực hành này chúng ta sẽ sử dụng thư viện Scikit-Learn (TfidfVectorizer) https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html**"
      ],
      "metadata": {
        "id": "VlqXIRRxKsHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo đối tượng TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Chúng ta sẽ tạo ra một tập danh sách các tài liệu/văn bản dạng list đơn giản để thư viện Scikit-Learn có thể đọc được\n",
        "sk_docs = []\n",
        "\n",
        "# Duyệt qua từng tài liệu/văn bản có trong (D)\n",
        "for (topic, normalized_doc, tokens) in D:\n",
        "  # Chúng ta sẽ nối các từ/tokens đã được tách để làm thành một văn bản hoàn chỉnh\n",
        "  text = ' '.join(tokens)\n",
        "  sk_docs.append(text)\n",
        "\n",
        "# Tiến hành chuyển đổi các tài liệu/văn bản về dạng các TF-IDF vectors\n",
        "tfidf_matrix = vectorizer.fit_transform(sk_docs)\n",
        "\n",
        "# Chuyển ma trận tfidf_matrix từ dạng cấu trúc thưa sang dạng đầy đủ để thuận tiện cho việc tính toán\n",
        "tfidf_matrix = tfidf_matrix.todense()"
      ],
      "metadata": {
        "id": "qwgfiKIiKsrs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiến hành thử nghiệm truy vấn tìm kiếm một số tài liệu/văn bản dựa trên truy vấn (q)**"
      ],
      "metadata": {
        "id": "tATVBX6uNIHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Viết hàm giúp chuyển đổi truy vấn dạng text sang tfidf vector\n",
        "def parse_query(query_text):\n",
        "  (normalized_doc, combined_tokens) = preprocess(query_text)\n",
        "  query_text = ' '.join(combined_tokens)\n",
        "  query_tfidf_vector = vectorizer.transform([query_text])[0].todense()\n",
        "  return query_tfidf_vector\n",
        "\n",
        "# Viết hàm giúp tìm kiếm top-k (mặc định 10) các kết quả tài liệu/văn bản tương đồng với truy vấn \n",
        "def search(query_tfidf_vector, top_k = 10):\n",
        "  search_results = {}\n",
        "  for doc_idx, doc_tfidf_vector in enumerate(tfidf_matrix):\n",
        "      # Tính mức độ tương đồng giữa truy vấn (q) và từng tài liệu/văn bản (doc_idx) bằng độ đo cosine\n",
        "      cs_score = 1 - distance.cosine(query_tfidf_vector, doc_tfidf_vector)\n",
        "      search_results[doc_idx] = cs_score\n",
        "  # Tiến hành sắp xếp các tài liệu/văn bản theo mức độ tương đồng từ cao -> thấp\n",
        "  sorted_search_results = sorted(search_results.items(), key=lambda item: item[1], reverse=True)\n",
        "  print('Top-[{}] tài liệu/văn bản có liên quan đến truy vấn.'.format(top_k))\n",
        "  for idx, (doc_idx, sim_score) in enumerate(sorted_search_results[:top_k]):\n",
        "    print(' - [{}]. Tài liệu [{}], chủ đề: [{}] -> mức độ tương đồng: [{:.6f}]'.format(idx + 1, doc_idx, doc_idx_topic_dict[doc_idx], sim_score))"
      ],
      "metadata": {
        "id": "NFrRdEo-OjD1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thử một truy vấn với chủ đề [the-thao]\n",
        "query_text = 'bóng đá'\n",
        "\n",
        "# Chuyển đổi truy vấn về dạng vector tfidf\n",
        "query_tfidf_vector = parse_query(query_text)\n",
        "\n",
        "# Chúng ta sẽ thử tìm kiếm với top-10 kết quả\n",
        "top_k = 10\n",
        "\n",
        "# Tiến hành tìm kiếm thử trong tập dữ liệu với truy vấn\n",
        "search(query_tfidf_vector, top_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHN3kfsITypw",
        "outputId": "83556c14-1bab-4bd1-eb0e-ce34cb90e149"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-[10] tài liệu/văn bản có liên quan đến truy vấn.\n",
            " - [1]. Tài liệu [14], chủ đề: [the-thao] -> mức độ tương đồng: [0.138164]\n",
            " - [2]. Tài liệu [35], chủ đề: [the-thao] -> mức độ tương đồng: [0.084354]\n",
            " - [3]. Tài liệu [103], chủ đề: [khoa-hoc] -> mức độ tương đồng: [0.072400]\n",
            " - [4]. Tài liệu [34], chủ đề: [the-thao] -> mức độ tương đồng: [0.029059]\n",
            " - [5]. Tài liệu [107], chủ đề: [khoa-hoc] -> mức độ tương đồng: [0.027820]\n",
            " - [6]. Tài liệu [12], chủ đề: [the-thao] -> mức độ tương đồng: [0.027710]\n",
            " - [7]. Tài liệu [21], chủ đề: [the-thao] -> mức độ tương đồng: [0.026200]\n",
            " - [8]. Tài liệu [18], chủ đề: [the-thao] -> mức độ tương đồng: [0.025886]\n",
            " - [9]. Tài liệu [26], chủ đề: [the-thao] -> mức độ tương đồng: [0.025115]\n",
            " - [10]. Tài liệu [33], chủ đề: [the-thao] -> mức độ tương đồng: [0.024014]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chúng ta có thể thấy kết quả trên có một số tài liệu có nhãn chủ đề là [khoa-hoc] (tài liệu có mã: 108, 101) có thể không liên quan đến truy vấn - do đó, đóng vai trò là người dùng, chúng ta sẽ:**\n",
        "\n",
        "*   Chọn tất cả các tài liệu/văn bản có nhãn chủ đề là [khoa-hoc], vào tập: $D_{irel}$\n",
        "*   Và chọn tất cả các tài liệu/văn bản có nhãn chủ đề là [the-thao], vào tập: $D_{rel}$"
      ],
      "metadata": {
        "id": "cz5hwRqTYcow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xác định danh sách các tài liệu/văn bản có liên quan (D_rel) và không liên quan (D_irel) đến truy vấn (q)\n",
        "D_rel = [27, 32, 0, 33, 24, 19, 7, 5]\n",
        "D_irel = [108, 101]"
      ],
      "metadata": {
        "id": "F2wudkwVUyrj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiến hành mở rộng/tái cấu trúc lại truy vấn với phép công và trừ vectors. Cụ thể:\n",
        "\n",
        "*   Với tập $D_{rel}$ ($d^{rel} \\in D_{rel}$): $$\\vec{q}^{QR}=\\vec{q}+\\vec{d}^{rel}$$\n",
        "*   Với tập $D_{irel}$ ($d^{irel} \\in D_{irel}$): $$\\vec{q}^{QR}=\\vec{q}\\vec{d}^{irel}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "FbVUufZ6ZXYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo mới một query mở rộng [query_tfidf_vector_QR] cho [query_tfidf_vector]\n",
        "query_tfidf_vector_QR = query_tfidf_vector\n",
        "\n",
        "# Với tập (D_rel) tiến hành cộng các tfidf vector của các tài liệu/văn bản trong đó với query_tfidf_vector_QR\n",
        "for doc_idx in D_rel:\n",
        "  doc_tfidf_vector_rel = tfidf_matrix[doc_idx]\n",
        "  query_tfidf_vector_QR += doc_tfidf_vector_rel\n",
        "\n",
        "# Với tập (D_irel) tiến hành trừ các tfidf vector của các tài liệu/văn bản trong đó với query_tfidf_vector_QR\n",
        "for doc_idx in D_irel:\n",
        "  doc_tfidf_vector_irel = tfidf_matrix[doc_idx]\n",
        "  query_tfidf_vector_QR -= doc_tfidf_vector_irel"
      ],
      "metadata": {
        "id": "cs27qcPKZUAo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chúng ta tiến hành thử truy vấn lại các văn bản/tài liệu với truy vấn đã được mở rộng/tái cấu trúc [query_tfidf_vector_QR]**"
      ],
      "metadata": {
        "id": "0Tm5PyQicgpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiến hành tìm kiếm lại với truy vấn mới[query_tfidf_vector_QR]\n",
        "search(query_tfidf_vector_QR, top_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-F5pFd0XW-K",
        "outputId": "ac25a56b-a453-4116-9345-8e483aae8863"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-[10] tài liệu/văn bản có liên quan đến truy vấn.\n",
            " - [1]. Tài liệu [33], chủ đề: [the-thao] -> mức độ tương đồng: [0.472643]\n",
            " - [2]. Tài liệu [5], chủ đề: [the-thao] -> mức độ tương đồng: [0.465699]\n",
            " - [3]. Tài liệu [7], chủ đề: [the-thao] -> mức độ tương đồng: [0.444015]\n",
            " - [4]. Tài liệu [0], chủ đề: [the-thao] -> mức độ tương đồng: [0.440115]\n",
            " - [5]. Tài liệu [32], chủ đề: [the-thao] -> mức độ tương đồng: [0.416658]\n",
            " - [6]. Tài liệu [19], chủ đề: [the-thao] -> mức độ tương đồng: [0.380849]\n",
            " - [7]. Tài liệu [29], chủ đề: [the-thao] -> mức độ tương đồng: [0.372405]\n",
            " - [8]. Tài liệu [27], chủ đề: [the-thao] -> mức độ tương đồng: [0.364751]\n",
            " - [9]. Tài liệu [24], chủ đề: [the-thao] -> mức độ tương đồng: [0.364675]\n",
            " - [10]. Tài liệu [9], chủ đề: [the-thao] -> mức độ tương đồng: [0.342513]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chúng ta có thể thấy các tài liệu với chủ đề [the-thao] đã được đẩy về lên trên trong danh sách top kết quả tìm kiếm và các tài liệu/văn bản [khoa-hoc] đã bị đẩy xuống dưới - không nằm trong top các kết quả nữa**"
      ],
      "metadata": {
        "id": "uKjmiZF7cSux"
      }
    }
  ]
}