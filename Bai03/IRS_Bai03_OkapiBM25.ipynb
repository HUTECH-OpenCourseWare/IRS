{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import các thư viện cần thiết**"
      ],
      "metadata": {
        "id": "6FkGBoya3WLK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgUJG3RA3NNf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tập dữ liệu văn bản/tài liệu mẫu và truy vấn**"
      ],
      "metadata": {
        "id": "mCk5ee4t3bCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tập văn bản/tài liệu (D)\n",
        "docs = [\n",
        "    'data mining is awesome. data mining helps to find frequent itemsets in database.',\n",
        "    'information retrieval is cool. information retrieval helps to search data quickly.',\n",
        "    'natural language processing is interesting. it helps computer to better understand text.'\n",
        "];\n",
        "\n",
        "# Truy vấn (q)\n",
        "query = 'information retrieval'\n",
        "\n",
        "# Để cho tiện lợi trong việc xử lý chúng ta sẽ gán câu truy vấn là 1 tài liệu cuối cùng\n",
        "docs.append(query)\n",
        "\n",
        "# Làm sạch văn bản - xóa các ký tự đặc biệt, dấu câu, v.v.\n",
        "docs = [re.sub('\\W+',' ', doc) for doc in docs] \n",
        "\n",
        "doc_len = len(docs)"
      ],
      "metadata": {
        "id": "SAJQgP0R3X_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Đọc từng tài liệu/văn bản và thực hiện tách từ - gán id cho các token và xây dựng tập từ vựng**\n",
        "\n",
        "**Ngoài ra chúng ta cũng cần xác định thêm các thông tin khác, bao gồm:**\n",
        "\n",
        "*   **Số lần xuất hiện của mỗi token/từ trong mỗi văn bản (term frequency)**\n",
        "*   **Số lượng văn bản mà mỗi token/từ xuất hiện (xét trong toàn tập văn bản)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-pDJBk6n3jAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cấu trúc dữ liệu dạng dictionary -> <key: id, value: token>\n",
        "id_token_dict = {}\n",
        "\n",
        "# Cấu trúc dữ liệu dạng dictionary -> <key: token, value: id>\n",
        "token_id_dict = {}\n",
        "\n",
        "# Cấu trúc dữ liệu dạng dictionary -> <key: doc_id, value: [id_token_xuất_hiện_1, id_token_xuất_hiện_2, v.v. ]>\n",
        "doc_id_token_ids_dict = {}\n",
        "\n",
        "# Cấu trúc dữ liệu dạng dictionary -> <key: token_id, value: <key: doc_id, value: token_freq>\n",
        "token_id_doc_id_term_freq_dict = {}\n",
        "\n",
        "# Cấu trúc dữ liệu dạng dictionary -> <key: doc_id, value: <key: token_id, value: token_freq>\n",
        "doc_id_token_id_term_freq_dict = {}\n",
        "\n",
        "# Cấu trúc dữ liệu dạng dictionary -> <key: token_id, value: [doc_id_token_xuất_hiện_1, doc_id_token_xuất_hiện_2, v.v.]>\n",
        "token_id_doc_ids_dict = {}\n",
        "\n",
        "# Gán id của token đầu tiên là [0]\n",
        "token_id = 0\n",
        "\n",
        "# Duyệt qua từng tài liệu/văn bản có trong mảng\n",
        "for doc_idx, doc in enumerate(docs):\n",
        "  # Tách các từ riêng biệt trong tài liệu/văn bản bằng khoảng trắng \" \"\n",
        "  tokens = doc.split(' ')\n",
        "  \n",
        "  # Khởi tạo danh sách các token_ids xuất hiện trong tài liệu/văn bản\n",
        "  doc_token_ids = []\n",
        "\n",
        "  # Đọc qua từng token trong mỗi tài liệu/văn bản\n",
        "  for token in tokens:\n",
        "    # Kiểm tra chiều dài từ khóa > 0\n",
        "    if len(token) > 0:\n",
        "      if token not in token_id_dict.keys():\n",
        "        token_id_dict[token] = token_id\n",
        "        id_token_dict[token_id] = token\n",
        "        # Tăng id của token tiếp theo lên 1\n",
        "        token_id+=1\n",
        "\n",
        "      target_token_id = token_id_dict[token]\n",
        "\n",
        "      # Đếm số lượng mà token này xuất hiện trong doc_idx\n",
        "      if target_token_id not in token_id_doc_id_term_freq_dict.keys():\n",
        "        token_id_doc_id_term_freq_dict[target_token_id] = {}\n",
        "        token_id_doc_id_term_freq_dict[target_token_id][doc_idx] = 1\n",
        "      else:\n",
        "        if doc_idx not in token_id_doc_id_term_freq_dict[target_token_id].keys():\n",
        "          token_id_doc_id_term_freq_dict[target_token_id][doc_idx] = 1\n",
        "        else:\n",
        "          token_id_doc_id_term_freq_dict[target_token_id][doc_idx] += 1\n",
        "      \n",
        "      if doc_idx not in doc_id_token_id_term_freq_dict.keys():\n",
        "        doc_id_token_id_term_freq_dict[doc_idx] = {}\n",
        "        doc_id_token_id_term_freq_dict[doc_idx][target_token_id] = 1\n",
        "      else:\n",
        "        if token_id not in doc_id_token_id_term_freq_dict[doc_idx].keys():\n",
        "          doc_id_token_id_term_freq_dict[doc_idx][target_token_id] = 1\n",
        "        else:\n",
        "          doc_id_token_id_term_freq_dict[doc_idx][target_token_id] += 1\n",
        "\n",
        "      # Gán doc_idx vào danh sách mà token này xuất hiện\n",
        "      if target_token_id not in token_id_doc_ids_dict.keys():\n",
        "        token_id_doc_ids_dict[target_token_id] = [doc_idx]\n",
        "      else:\n",
        "        if doc_idx not in token_id_doc_ids_dict[target_token_id]:\n",
        "          token_id_doc_ids_dict[target_token_id].append(doc_idx)\n",
        "\n",
        "      doc_token_ids.append(token_id_dict[token])\n",
        "  doc_id_token_ids_dict[doc_idx] = doc_token_ids\n",
        "\n",
        "# Xuất ra màn hình kích thước tập từ vựng (vocabulary)\n",
        "vocab_size = len(id_token_dict.keys())\n",
        "print('Kích thước tập từ vựng: [{}]'.format(vocab_size))\n",
        "print('Tập từ vựng (V):')\n",
        "print(id_token_dict)\n",
        "print('---')\n",
        "print('Thông tin về tầng số xuất hiện của từ trong mỗi tài liệu/văn bản:')\n",
        "print(token_id_doc_id_term_freq_dict)\n",
        "print(doc_id_token_id_term_freq_dict)\n",
        "print('---')\n",
        "print('Thông tin về từ - danh sách các tài liệu/văn bản mà nó xuất hiện:')\n",
        "print(token_id_doc_ids_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXCEyD0v3g-A",
        "outputId": "e5f7dc25-7fc6-4176-9f64-47990322369b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kích thước tập từ vựng: [25]\n",
            "Tập từ vựng (V):\n",
            "{0: 'data', 1: 'mining', 2: 'is', 3: 'awesome', 4: 'helps', 5: 'to', 6: 'find', 7: 'frequent', 8: 'itemsets', 9: 'in', 10: 'database', 11: 'information', 12: 'retrieval', 13: 'cool', 14: 'search', 15: 'quickly', 16: 'natural', 17: 'language', 18: 'processing', 19: 'interesting', 20: 'it', 21: 'computer', 22: 'better', 23: 'understand', 24: 'text'}\n",
            "---\n",
            "Thông tin về tầng số xuất hiện của từ trong mỗi tài liệu/văn bản:\n",
            "{0: {0: 2, 1: 1}, 1: {0: 2}, 2: {0: 1, 1: 1, 2: 1}, 3: {0: 1}, 4: {0: 1, 1: 1, 2: 1}, 5: {0: 1, 1: 1, 2: 1}, 6: {0: 1}, 7: {0: 1}, 8: {0: 1}, 9: {0: 1}, 10: {0: 1}, 11: {1: 2, 3: 1}, 12: {1: 2, 3: 1}, 13: {1: 1}, 14: {1: 1}, 15: {1: 1}, 16: {2: 1}, 17: {2: 1}, 18: {2: 1}, 19: {2: 1}, 20: {2: 1}, 21: {2: 1}, 22: {2: 1}, 23: {2: 1}, 24: {2: 1}}\n",
            "{0: {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1}, 1: {11: 1, 12: 1, 2: 1, 13: 1, 4: 1, 5: 1, 14: 1, 0: 1, 15: 1}, 2: {16: 1, 17: 1, 18: 1, 2: 1, 19: 1, 20: 1, 4: 1, 21: 1, 5: 1, 22: 1, 23: 1, 24: 1}, 3: {11: 1, 12: 1}}\n",
            "---\n",
            "Thông tin về từ - danh sách các tài liệu/văn bản mà nó xuất hiện:\n",
            "{0: [0, 1], 1: [0], 2: [0, 1, 2], 3: [0], 4: [0, 1, 2], 5: [0, 1, 2], 6: [0], 7: [0], 8: [0], 9: [0], 10: [0], 11: [1, 3], 12: [1, 3], 13: [1], 14: [1], 15: [1], 16: [2], 17: [2], 18: [2], 19: [2], 20: [2], 21: [2], 22: [2], 23: [2], 24: [2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thực hiện tính độ tương đồng và xếp hạng truy vấn (q) và các tài liệu/văn bản, ký hiệu: $sim_{BM25}(d,q)$. Với mỗi tài liệu/văn bản ($d$), ta có:**\n",
        "## $$sim_{BM25}(d,q)=\\sum^{n}_{i=1}IDF(q_{i}).\\frac{f(q_{i},d).(k+1)}{f(q_{i},d)+k.\\left(1-b+b.\\frac{|d|}{avgdl}\\right)}$$"
      ],
      "metadata": {
        "id": "A-j39koW8KIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Thiết lập hai hằng số mô mình (k) và (b)\n",
        "k = 1.2\n",
        "b = 0.75\n",
        "\n",
        "# Tính chiều dài trung bình của tập tài liệu/văn bản [avgdl]\n",
        "total_doc_length = 0\n",
        "doc_idxes = list(doc_id_token_id_term_freq_dict.keys())[0:doc_len-1]\n",
        "total_docs = len(doc_idxes)\n",
        "for doc_idx in doc_idxes:\n",
        "  total_doc_length += len(doc_id_token_id_term_freq_dict[doc_idx])\n",
        "\n",
        "avgdl = total_doc_length / total_docs\n",
        "print(f'Chiều dài trung bình của tập tài liệu: [{avgdl:.3f}]')\n",
        "\n",
        "# Viết hàm tính trọng số IDF của một từ khoá (qi) trong truy vấn\n",
        "def calc_idf(token_idx):\n",
        "  df = len(token_id_doc_ids_dict[token_idx])\n",
        "  idf = math.log((total_docs / df), 2)\n",
        "  return idf\n",
        "\n",
        "# Viết hàm tính trọng số Okapi BM25 của truy vấn (q) và tài liệu (d)\n",
        "def calc_okapi_bm25(doc_idx):\n",
        "  okapi_bm25_score = 0\n",
        "  doc_token_idx_freq_dict = doc_id_token_id_term_freq_dict[doc_idx]\n",
        "  doc_idx_len = len(doc_token_idx_freq_dict.keys())\n",
        "  query_token_idx_freq_dict = doc_id_token_id_term_freq_dict[doc_len-1]\n",
        "  for token_idx in query_token_idx_freq_dict.keys():\n",
        "    f_qi_d = 0\n",
        "    if token_idx in doc_token_idx_freq_dict.keys():\n",
        "      f_qi_d = doc_token_idx_freq_dict[token_idx]\n",
        "    idf = calc_idf(token_idx)\n",
        "    okapi_bm25_score += idf * ((f_qi_d * (k + 1)) / \n",
        "      (f_qi_d + k *(1 - b + b * (doc_idx_len / avgdl))))\n",
        "  return okapi_bm25_score\n",
        "\n",
        "print('Tiến hành tính độ tương đồng Okapi BM25 của truy vấn (q) với tập tài liệu/văn bản...')\n",
        "for doc_idx in doc_idxes:\n",
        "  okapi_bm25_score = calc_okapi_bm25(doc_idx)\n",
        "  print(f' - Độ tương đồng Okapi BM25 của tài liệu/văn bản thứ [{doc_idx}] = [{okapi_bm25_score:.3f}]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3HgeUir8_fh",
        "outputId": "259621f4-317d-4562-a460-719fe0347368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chiều dài trung bình của tập tài liệu: [10.667]\n",
            "Tiến hành tính độ tương đồng Okapi BM25 của truy vấn (q) với tập tài liệu/văn bản...\n",
            " - Độ tương đồng Okapi BM25 của tài liệu/văn bản thứ [0] = [0.000]\n",
            " - Độ tương đồng Okapi BM25 của tài liệu/văn bản thứ [1] = [1.250]\n",
            " - Độ tương đồng Okapi BM25 của tài liệu/văn bản thứ [2] = [0.000]\n"
          ]
        }
      ]
    }
  ]
}