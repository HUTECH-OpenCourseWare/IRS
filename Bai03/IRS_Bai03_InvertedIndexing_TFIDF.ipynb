{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Cài đặt thư viện UnderTheSea để hỗ trợ tách từ trong tiếng Việt. Xem thêm các tính năng của thư viện tại: https://github.com/undertheseanlp/underthesea**"
      ],
      "metadata": {
        "id": "8ehF74lN9uT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGYIOJKw9vKt",
        "outputId": "704f15ab-a659-4a91-f53a-7365d1a8ed19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-1.3.5-py3-none-any.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 4.9 MB/s \n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from underthesea) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from underthesea) (6.0)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from underthesea) (3.7)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from underthesea) (1.2.0)\n",
            "Collecting underthesea-core==0.0.5a2\n",
            "  Downloading underthesea_core-0.0.5_alpha.2-cp38-cp38-manylinux2010_x86_64.whl (591 kB)\n",
            "\u001b[K     |████████████████████████████████| 591 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from underthesea) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->underthesea) (2022.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Installing collected packages: unidecode, underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-1.3.5 underthesea-core-0.0.5a2 unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import các thư viện cần thiết**"
      ],
      "metadata": {
        "id": "rMZguF7w9sLG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxvcvpVk9kWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from underthesea import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cho một tập dữ liệu (D) mẫu như bến dưới**"
      ],
      "metadata": {
        "id": "vrp-yADozsih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khai báo tập tài liệu/văn bản\n",
        "D = [\n",
        "    'Khai phá dữ liệu (data mining) Là quá trình tính toán để tìm ra các mẫu trong các bộ dữ liệu lớn liên quan đến các phương pháp tại giao điểm của máy học, thống kê và các hệ thống cơ sở dữ liệu. Đây là một lĩnh vực liên ngành của khoa học máy tính.',\n",
        "    'Truy hồi thông tin (information retrieval) là hoạt động thu thập các nguồn thông tin liên quan đến một thông tin cần tìm kiếm, có thể dựa trên dữ liệu và trên việc đánh chỉ mục toàn văn.',\n",
        "    'Xử lý ngôn ngữ tự nhiên (natural language processing) là một nhánh cực kỳ quan trọng của trí tuệ nhân tạo (AI), là giao điểm của ngôn ngữ học và khoa học máy tính. NLP làm nhiệm vụ xử lý và phân tích một lượng lớn dữ liệu ngôn ngữ tự nhiên để bắt chước các tương tác giữa con người theo cách giống con người.'\n",
        "]\n",
        "\n",
        "# Xác định số lượng tài liệu/văn bản\n",
        "doc_size = len(D)"
      ],
      "metadata": {
        "id": "EGqMN9iFztFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiến hành tách từ và xây dựng tập từ vựng ở dạng chỉ mục ngược (inverted_index)**"
      ],
      "metadata": {
        "id": "CfANpPp291Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xây dựng tập từ vựng (V) dạng cấu trúc chỉ mục ngược\n",
        "# (V) là cấu trúc dữ liệu dạng dictionary <key: token_1, value: [(doc_idx_1, tf(token_1)), (doc_idx_2, tf(token_1)), v.v.>\n",
        "inverted_index = {}\n",
        "\n",
        "# Chúng cũng cần xác định trọng số lớn nhất của từ xuất hiện trong mỗi tài liệu/văn bản để cập nhật lại tf\n",
        "# Cấu trúc dữ liệu dạng dictionary <key: doc_idx, value: <key: token, value: token_freq>>\n",
        "doc_idx_token_token_freq = {}\n",
        "\n",
        "# Tiến hành duyệt qua từng văn bản để xây dựng tập từ vựng\n",
        "for doc_idx, doc in enumerate(D):\n",
        "  # Để thuận tiện ta sẽ chuyển tất cả các từ trong các tài liệu/văn bản về dạng lowercase\n",
        "  doc = doc.lower()\n",
        "  \n",
        "  # Xóa bỏ các ký tự đặc biệt\n",
        "  clean_doc = re.sub('\\W+',' ', doc)\n",
        "  \n",
        "  # Tiến hành dùng thư viện UnderTheSea để tách các từ/token trong tiếng Việt\n",
        "  tokens = word_tokenize(clean_doc)\n",
        "  \n",
        "  # Tiến hành thay thế các khoảng trắng ' ' trong các từ ghép thành '_'\n",
        "  tokens = [token.replace(' ', '_') for token in tokens]\n",
        "\n",
        "  # Duyệt qua từng token\n",
        "  for token in tokens:\n",
        "    # Kiểm tra xem token đã tồn tại trong tập từ vựng (V) hay chưa\n",
        "    if token not in inverted_index.keys():\n",
        "      inverted_index[token] = [(doc_idx, 1)]\n",
        "    else:\n",
        "      # Kiểm tra xem tài liệu doc_idx đã có trong danh sách các tài liệu chỉ mục ngược của token này hay chưa\n",
        "      is_existed = False\n",
        "      for inverted_data_idx, (target_doc_idx, target_tf) in enumerate(inverted_index[token]):\n",
        "        if target_doc_idx == doc_idx:\n",
        "          # Tăng tần số xuất hiện của token trong tài liệu (target_doc_idx) lên 1\n",
        "          target_tf+=1\n",
        "          # Cập nhật lại dữ liệu\n",
        "          inverted_index[token][inverted_data_idx] = (target_doc_idx, target_tf)\n",
        "          is_existed = True\n",
        "          break\n",
        "      # Trường hợp chưa tồn tại\n",
        "      if is_existed == False:\n",
        "        inverted_index[token].append((doc_idx, 1))\n",
        "    \n",
        "      if doc_idx not in doc_idx_token_token_freq.keys():\n",
        "        doc_idx_token_token_freq[doc_idx] = {}\n",
        "        doc_idx_token_token_freq[doc_idx][token] = 1\n",
        "      else:\n",
        "        if token not in doc_idx_token_token_freq[doc_idx].keys():\n",
        "          doc_idx_token_token_freq[doc_idx][token] = 1\n",
        "        else:\n",
        "          doc_idx_token_token_freq[doc_idx][token] += 1"
      ],
      "metadata": {
        "id": "Rj2Dpyw2-Anu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cập nhật lại tf của từng token trong danh sách các tài liệu/văn bản chỉ mục ngược. Vì hiện tại giá trị tf của chúng ta chỉ là số lần xuất hiện của từ/token trong mỗi tài liệu**\n",
        "\n",
        "**Nhưng tf cửa 1 từ (i) trong tài liệu/văn bản (j), ký hiệu: ($tf_{ij}$) lại được xác định là**: $$tf_{ij}=\\frac{f_{ij}}{max_i(f_{ij})}$$"
      ],
      "metadata": {
        "id": "6LuijsEg77wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm tìm từ khóa/token xuất hiện nhiều nhất trong một tài liệu/văn bản (doc_idx)\n",
        "def find_max_freq_token(doc_idx):\n",
        "  max_freq_token = ''\n",
        "  max_freq = 0\n",
        "  tokens = doc_idx_token_token_freq[doc_idx]\n",
        "  for token in doc_idx_token_token_freq[doc_idx].keys():\n",
        "    if doc_idx_token_token_freq[doc_idx][token] > max_freq:\n",
        "      max_freq_token = token\n",
        "      max_freq = doc_idx_token_token_freq[doc_idx][token]\n",
        "  return (max_freq_token, max_freq)\n",
        "\n",
        "# Cấu trúc dữ liệu dạng dictionary <key: doc_idx, value: (max_freq_token, max_freq)>\n",
        "doc_idx_max_freq_token = {}\n",
        "for doc_idx, doc in enumerate(D):\n",
        "  doc_idx_max_freq_token[doc_idx] = find_max_freq_token(doc_idx)\n",
        "\n",
        "# Cập nhật lại tf của từng token trong danh sách các tài liệu/văn bản chỉ mục ngược\n",
        "for token in inverted_index.keys():\n",
        "  D_t = inverted_index[token]\n",
        "  for inverted_data_idx, (doc_idx, tf) in enumerate(D_t):\n",
        "    # Cập nhật lại trọng số tf của token đang xét\n",
        "    (max_freq_token, max_freq) = doc_idx_max_freq_token[doc_idx]\n",
        "    update_tf = tf / max_freq\n",
        "    # Cập nhật lại dữ liệu\n",
        "    inverted_index[token][inverted_data_idx] = (doc_idx, update_tf)"
      ],
      "metadata": {
        "id": "HwJHVOut78vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In danh sách các token/từ khóa và các tài liệu/văn bản mà nó xuất hiện dạng chỉ mục ngược ra màn hình**"
      ],
      "metadata": {
        "id": "hzoHhSqVyluE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in inverted_index.keys():\n",
        "  print(token, '->', inverted_index[token])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT_19a9kywjm",
        "outputId": "da8fa0b2-a2e7-481d-8020-d0da5b4356e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "khai_phá -> [(0, 0.3333333333333333)]\n",
            "dữ_liệu -> [(0, 1.0), (1, 0.5), (2, 0.5)]\n",
            "data -> [(0, 0.3333333333333333)]\n",
            "mining -> [(0, 0.3333333333333333)]\n",
            "là -> [(0, 0.6666666666666666), (1, 0.5), (2, 1.0)]\n",
            "quá_trình -> [(0, 0.3333333333333333)]\n",
            "tính_toán -> [(0, 0.3333333333333333)]\n",
            "để -> [(0, 0.3333333333333333), (2, 0.5)]\n",
            "tìm -> [(0, 0.3333333333333333)]\n",
            "ra -> [(0, 0.3333333333333333)]\n",
            "các -> [(0, 1.3333333333333333), (1, 0.5), (2, 0.5)]\n",
            "mẫu -> [(0, 0.3333333333333333)]\n",
            "trong -> [(0, 0.3333333333333333)]\n",
            "bộ -> [(0, 0.3333333333333333)]\n",
            "lớn -> [(0, 0.3333333333333333), (2, 0.5)]\n",
            "liên_quan -> [(0, 0.3333333333333333), (1, 0.5)]\n",
            "đến -> [(0, 0.3333333333333333), (1, 0.5)]\n",
            "phương_pháp -> [(0, 0.3333333333333333)]\n",
            "tại -> [(0, 0.3333333333333333)]\n",
            "giao_điểm -> [(0, 0.3333333333333333), (2, 0.5)]\n",
            "của -> [(0, 0.6666666666666666), (2, 1.0)]\n",
            "máy -> [(0, 0.3333333333333333)]\n",
            "học -> [(0, 0.3333333333333333)]\n",
            "thống_kê -> [(0, 0.3333333333333333)]\n",
            "và -> [(0, 0.3333333333333333), (1, 0.5), (2, 1.0)]\n",
            "hệ_thống -> [(0, 0.3333333333333333)]\n",
            "cơ_sở -> [(0, 0.3333333333333333)]\n",
            "đây -> [(0, 0.3333333333333333)]\n",
            "một -> [(0, 0.3333333333333333), (1, 0.5), (2, 1.0)]\n",
            "lĩnh_vực -> [(0, 0.3333333333333333)]\n",
            "liên_ngành -> [(0, 0.3333333333333333)]\n",
            "khoa_học -> [(0, 0.3333333333333333), (2, 0.5)]\n",
            "máy_tính -> [(0, 0.3333333333333333), (2, 0.5)]\n",
            "truy -> [(1, 0.5)]\n",
            "hồi -> [(1, 0.5)]\n",
            "thông_tin -> [(1, 1.5)]\n",
            "information -> [(1, 0.5)]\n",
            "retrieval -> [(1, 0.5)]\n",
            "hoạt_động -> [(1, 0.5)]\n",
            "thu_thập -> [(1, 0.5)]\n",
            "nguồn -> [(1, 0.5)]\n",
            "cần -> [(1, 0.5)]\n",
            "tìm_kiếm -> [(1, 0.5)]\n",
            "có_thể -> [(1, 0.5)]\n",
            "dựa -> [(1, 0.5)]\n",
            "trên -> [(1, 1.0)]\n",
            "việc -> [(1, 0.5)]\n",
            "đánh -> [(1, 0.5)]\n",
            "chỉ -> [(1, 0.5)]\n",
            "mục -> [(1, 0.5)]\n",
            "toàn_văn -> [(1, 0.5)]\n",
            "xử_lý -> [(2, 1.0)]\n",
            "ngôn_ngữ -> [(2, 1.0)]\n",
            "tự_nhiên -> [(2, 1.0)]\n",
            "natural -> [(2, 0.5)]\n",
            "language -> [(2, 0.5)]\n",
            "processing -> [(2, 0.5)]\n",
            "nhánh -> [(2, 0.5)]\n",
            "cực_kỳ -> [(2, 0.5)]\n",
            "quan_trọng -> [(2, 0.5)]\n",
            "trí_tuệ -> [(2, 0.5)]\n",
            "nhân_tạo -> [(2, 0.5)]\n",
            "ai -> [(2, 0.5)]\n",
            "ngôn_ngữ_học -> [(2, 0.5)]\n",
            "nlp -> [(2, 0.5)]\n",
            "làm -> [(2, 0.5)]\n",
            "nhiệm_vụ -> [(2, 0.5)]\n",
            "phân_tích -> [(2, 0.5)]\n",
            "lượng -> [(2, 0.5)]\n",
            "bắt_chước -> [(2, 0.5)]\n",
            "tương_tác -> [(2, 0.5)]\n",
            "giữa -> [(2, 0.5)]\n",
            "con_người -> [(2, 1.0)]\n",
            "theo -> [(2, 0.5)]\n",
            "cách -> [(2, 0.5)]\n",
            "giống -> [(2, 0.5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Áp dụng tập từ vựng ở dạng dữ liệu chỉ mục ngược và tính trọng số TF-IDF của mỗi từ/token với mỗi văn bản. Với công thức TF-IDF được xác định như sau**\n",
        "$$ TF-IDF = TF \\times IDF $$\n",
        "**Và**: $$IDF = log_{2}(\\frac{|D|}{df_{i}})$$"
      ],
      "metadata": {
        "id": "uz05y79zzk5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in inverted_index.keys():\n",
        "  # Lấy ra danh sách các tài liệu/văn bản mà từ vựng này xuất hiện\n",
        "  D_t = inverted_index[token]\n",
        "  # Từ đó, ta xác định được doc_freq (df)\n",
        "  doc_freq = len(D_t)\n",
        "  for (doc_idx, tf) in D_t:\n",
        "    idf = math.log((doc_size / doc_freq),2)\n",
        "    tfidf = tf * idf\n",
        "    print('Từ: [',token, ']-> tài liệu số: [', doc_idx, '], TF-IDF = [', tfidf, ']')\n",
        "  print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0in0cXdzdrz",
        "outputId": "567955a7-8194-4304-b941-9c1b639be888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Từ: [ khai_phá ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ dữ_liệu ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ dữ_liệu ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ dữ_liệu ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.0 ]\n",
            "---\n",
            "Từ: [ data ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ mining ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ là ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ là ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ là ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.0 ]\n",
            "---\n",
            "Từ: [ quá_trình ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ tính_toán ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ để ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ để ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ tìm ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ ra ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ các ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ các ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ các ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.0 ]\n",
            "---\n",
            "Từ: [ mẫu ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ trong ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ bộ ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ lớn ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ lớn ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ liên_quan ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ liên_quan ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ đến ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ đến ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ phương_pháp ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ tại ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ giao_điểm ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ giao_điểm ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ của ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.3899750004807708 ]\n",
            "Từ: [ của ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.5849625007211562 ]\n",
            "---\n",
            "Từ: [ máy ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ học ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ thống_kê ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ và ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ và ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ và ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.0 ]\n",
            "---\n",
            "Từ: [ hệ_thống ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ cơ_sở ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ đây ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ một ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ một ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.0 ]\n",
            "Từ: [ một ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.0 ]\n",
            "---\n",
            "Từ: [ lĩnh_vực ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ liên_ngành ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.5283208335737187 ]\n",
            "---\n",
            "Từ: [ khoa_học ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ khoa_học ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ máy_tính ]-> tài liệu số: [ 0 ], TF-IDF = [ 0.1949875002403854 ]\n",
            "Từ: [ máy_tính ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.2924812503605781 ]\n",
            "---\n",
            "Từ: [ truy ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ hồi ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ thông_tin ]-> tài liệu số: [ 1 ], TF-IDF = [ 2.3774437510817346 ]\n",
            "---\n",
            "Từ: [ information ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ retrieval ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ hoạt_động ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ thu_thập ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ nguồn ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ cần ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ tìm_kiếm ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ có_thể ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ dựa ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ trên ]-> tài liệu số: [ 1 ], TF-IDF = [ 1.5849625007211563 ]\n",
            "---\n",
            "Từ: [ việc ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ đánh ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ chỉ ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ mục ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ toàn_văn ]-> tài liệu số: [ 1 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ xử_lý ]-> tài liệu số: [ 2 ], TF-IDF = [ 1.5849625007211563 ]\n",
            "---\n",
            "Từ: [ ngôn_ngữ ]-> tài liệu số: [ 2 ], TF-IDF = [ 1.5849625007211563 ]\n",
            "---\n",
            "Từ: [ tự_nhiên ]-> tài liệu số: [ 2 ], TF-IDF = [ 1.5849625007211563 ]\n",
            "---\n",
            "Từ: [ natural ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ language ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ processing ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ nhánh ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ cực_kỳ ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ quan_trọng ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ trí_tuệ ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ nhân_tạo ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ ai ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ ngôn_ngữ_học ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ nlp ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ làm ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ nhiệm_vụ ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ phân_tích ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ lượng ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ bắt_chước ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ tương_tác ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ giữa ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ con_người ]-> tài liệu số: [ 2 ], TF-IDF = [ 1.5849625007211563 ]\n",
            "---\n",
            "Từ: [ theo ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ cách ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n",
            "Từ: [ giống ]-> tài liệu số: [ 2 ], TF-IDF = [ 0.7924812503605781 ]\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}