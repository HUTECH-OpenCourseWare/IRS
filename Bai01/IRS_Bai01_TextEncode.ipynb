{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivJX2JqErwQg"
   },
   "source": [
    "**Import các thư viện cần thiết**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QMPLDevirzav"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6-7pKQmr6NK"
   },
   "source": [
    "**Lấy dữ liệu các tài liệu/văn bản mẫu từ**: https://github.com/HUTECH-OpenCourseWare/IRS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJPiTrgMr1JP",
    "outputId": "cd8e1c02-ae04-44c7-ff01-38e5072b3cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'IRS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/HUTECH-OpenCourseWare/IRS.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNZgCTR3r-aw"
   },
   "source": [
    "**Đọc dữ liệu, tiền xử lý làm sạch các tài liệu/văn bản từ các files chứa trong folder \"/content/IRS_Course/data/vnexpress/<chủ_đề>\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "736bdsx9r9wX",
    "outputId": "39951edb-c66a-40da-a543-00f3ac7be251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc dữ liệu từ file: [liverpool-nhi-bang-tai-champions-league-4530835.txt]...\n",
      "Đọc dữ liệu từ file: [cac-phuong-an-thay-quang-hai-o-aff-cup-4530113.txt]...\n",
      "Đọc dữ liệu từ file: [su-that-thuong-cua-golfer-18-tuoi-lan-dau-du-pga-tour-4530793.txt]...\n",
      "Đọc dữ liệu từ file: [tundra-esports-bo-tui-8-5-trieu-usd-khi-vo-dich-dota2-the-gioi-4530586.txt]...\n",
      "Đọc dữ liệu từ file: [tottenham-vao-vong-1-8-champions-league-4530837.txt]...\n",
      "Đọc dữ liệu từ file: [clb-huong-loi-neu-co-cau-thu-tien-sau-o-world-cup-2022-4530090.txt]...\n",
      "Đọc dữ liệu từ file: [dien-bien-dao-chieu-lien-tuc-o-bang-d-champions-league-4530851.txt]...\n",
      "Đọc dữ liệu từ file: [bayern-ba-lan-toan-thang-vong-bang-champions-league-4530836.txt]...\n",
      "Đọc dữ liệu từ file: [ronaldo-mat-ngoi-vua-phong-tap-tai-man-utd-4530011.txt]...\n",
      "Đọc dữ liệu từ file: [klopp-hay-danh-gia-liverpool-vao-cuoi-mua-4530373.txt]...\n",
      "Đọc dữ liệu từ file: [golfer-nghiep-du-so-mot-viet-nam-danh-duoi-ky-vong-o-apac-4530323.txt]...\n",
      "Đọc dữ liệu từ file: [cac-clb-tap-cuong-do-cao-truoc-them-vm-hanoi-midnight-4528553.txt]...\n",
      "Đọc dữ liệu từ file: [lewandowski-barca-can-tinh-quai-hon-4530375.txt]...\n",
      "Đọc dữ liệu từ file: [roma-thang-nho-hai-ban-trong-bon-phut-cuoi-4530374.txt]...\n",
      "Đọc dữ liệu từ file: [v-league-2023-se-co-var-4530012.txt]...\n",
      "Đọc dữ liệu từ file: [ronaldo-sa-sut-the-nao-tai-ngoai-hang-anh-4530828.txt]...\n",
      "Đọc dữ liệu từ file: [djokovic-lich-su-phan-xet-ai-gioi-nhat-4530474.txt]...\n",
      "Đọc dữ liệu từ file: [hom-nay-xac-dinh-them-hai-suat-vong-1-8-champions-league-4530786.txt]...\n",
      "Đọc dữ liệu từ file: [nhat-ban-chot-doi-hinh-du-world-cup-2022-4530703.txt]...\n",
      "Đọc dữ liệu từ file: [drx-lap-ky-tich-tai-worlds-2022-4530137.txt]...\n",
      "Đọc dữ liệu từ file: [haaland-nghi-tran-thu-hai-lien-tiep-4530833.txt]...\n",
      "Đọc dữ liệu từ file: [v-league-tiep-tuc-moi-trong-tai-thai-lan-malaysia-4530320.txt]...\n",
      "Đọc dữ liệu từ file: [bao-chan-thuong-de-doa-argentina-4530209.txt]...\n",
      "Đọc dữ liệu từ file: [alcaraz-muon-giu-vi-tri-so-mot-toi-het-nam-4530537.txt]...\n",
      "Đọc dữ liệu từ file: [nha-vo-dich-marathon-nga-sap-sau-vach-dich-4530762.txt]...\n",
      "Đọc dữ liệu từ file: [ronaldo-that-bai-khi-thu-ky-thuat-cua-antony-4530430.txt]...\n",
      "Đọc dữ liệu từ file: [bao-thai-lan-kiatisuk-gap-thu-thach-lon-nhat-o-hagl-4530241.txt]...\n",
      "Đọc dữ liệu từ file: [verstappen-lap-ky-luc-thang-chang-trong-mot-mua-giai-4530139.txt]...\n",
      "Đọc dữ liệu từ file: [doi-cua-johnson-vo-dich-chung-ket-lon-invitational-series-4530322.txt]...\n",
      "Đọc dữ liệu từ file: [10-ngoi-sao-lui-tan-sau-khi-toa-sang-o-world-cup-4530689.txt]...\n",
      "Đọc dữ liệu từ file: [pogba-khong-du-world-cup-2022-4530384.txt]...\n",
      "Đọc dữ liệu từ file: [bay-cap-vo-chong-lap-nhom-chay-vm-hanoi-midnight-4527409.txt]...\n",
      "Đọc dữ liệu từ file: [neville-thay-doi-quan-diem-ve-man-utd-4529949.txt]...\n",
      "Đọc dữ liệu từ file: [man-city-dat-gia-nhat-chau-au-4530583.txt]...\n",
      "Đọc dữ liệu từ file: [ibrahimovic-ligue-1-chang-con-gi-de-noi-4530363.txt]...\n",
      "Đọc dữ liệu từ file: [vff-thu-gan-680-ty-dong-tai-tro-trong-khoa-8-4530570.txt]...\n",
      "Đọc dữ liệu từ file: [ly-hoang-nam-thua-nguoc-o-giai-lon-nhat-su-nghiep-4530544.txt]...\n",
      "Đọc dữ liệu từ file: [barca-chia-tay-champions-league-bang-tran-thang-4530848.txt]...\n",
      "Đọc dữ liệu từ file: [nhung-cach-de-chay-zone-2-4530461.txt]...\n"
     ]
    }
   ],
   "source": [
    "topic = 'the-thao'\n",
    "data_root_dir_path = '/content/IRS/data/vnexpress/{}'.format(topic)\n",
    "docs = []\n",
    "for file_name in os.listdir(data_root_dir_path):\n",
    "  print('Đọc dữ liệu từ file: [{}]...'.format(file_name))\n",
    "  file_path = os.path.join(data_root_dir_path, file_name)\n",
    "  with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    lines = []\n",
    "    # Đọc từng dòng trong file\n",
    "    for line in f:\n",
    "      # Chuyển đổi chuỗi về dạng chữ viết thường và xóa các khoảng trắng ở đầu/cuối mỗi dòng\n",
    "      line = line.lower().strip()\n",
    "      # Bỏ các dòng đọc được vào trong mảng lines\n",
    "      lines.append(line)\n",
    "  # Nối các dòng riêng biệt trong mảng lines thành một tài liệu/văn bản hoàn chỉnh\n",
    "  doc = \" \".join(lines)\n",
    "  # Làm sạch văn bản - xóa các ký tự đặc biệt, dấu câu, v.v.\n",
    "  clean_doc = re.sub('\\W+',' ', doc)\n",
    "  docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh-jHqvrsEN4"
   },
   "source": [
    "**Đọc từng tài liệu/văn bản và thực hiện tách từ - gán id cho các token và xây dựng tập từ vựng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZ_Z2sBAsOG-",
    "outputId": "1feb4645-67f3-4dec-b085-885924f709b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập từ vựng: [4135]\n"
     ]
    }
   ],
   "source": [
    "# Cấu trúc dữ liệu dạng dictionary -> <key: id, value: token>\n",
    "id_token_dict = {}\n",
    "\n",
    "# Cấu trúc dữ liệu dạng dictionary -> <key: token, value: id>\n",
    "token_id_dict = {}\n",
    "\n",
    "# Cấu trúc dữ liệu dạng dictionary -> <key: doc_id, value: [id_token_xuất_hiện_1, id_token_xuất_hiện_2, v.v. ]>\n",
    "doc_id_token_ids_dict = {}\n",
    "\n",
    "# Gán id của token đầu tiên là [0]\n",
    "token_id = 0 #4134\n",
    "\n",
    "# Duyệt qua từng tài liệu/văn bản có trong mảng\n",
    "for doc_idx, doc in enumerate(docs):\n",
    "  # Tách các từ riêng biệt trong tài liệu/văn bản bằng khoảng trắng \" \"\"\n",
    "  tokens = doc.split(' ')\n",
    "  \n",
    "  # Khởi tạo danh sách các token_ids xuất hiện trong tài liệu/văn bản\n",
    "  doc_token_ids = []\n",
    "\n",
    "  # Đọc qua từng token trong mỗi tài liệu/văn bản\n",
    "  for token in tokens:\n",
    "    # Kiểm tra chiều dài từ khóa > 0\n",
    "    if len(token) > 0:\n",
    "      if token not in token_id_dict.keys():\n",
    "        token_id_dict[token] = token_id\n",
    "        id_token_dict[token_id] = token\n",
    "        # Tăng id của token tiếp theo lên 1\n",
    "        token_id+=1\n",
    "\n",
    "      doc_token_ids.append(token_id_dict[token])\n",
    "  doc_id_token_ids_dict[doc_idx] = doc_token_ids\n",
    "\n",
    "# Xuất ra màn hình kích thước tập từ vựng (vocabulary)\n",
    "vocab_size = len(id_token_dict.keys())\n",
    "print('Kích thước tập từ vựng: [{}]'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbFspNTVuXJC"
   },
   "source": [
    "**Xem danh sách token_ids xuất hiện trong tài liệu/văn bản thứ [10]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeqzJCwkuZDR",
    "outputId": "9cc4fc3b-ce43-4ae9-d8bd-29b02daecef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[659, 703, 704, 44, 37, 208, 304, 161, 383, 851, 728, 9, 1713, 431, 1714, 31, 513, 309, 345, 1715, 388, 32, 1716, 36, 439, 256, 1717, 3, 1718, 691, 707, 1068, 9, 60, 711, 345, 1715, 18, 764, 36, 237, 37, 1719, 750, 836, 33, 60, 1720, 345, 388, 32, 1721, 47, 62, 247, 729, 9, 719, 715, 1722, 587, 1723, 1724, 723, 1710, 629, 1725, 439, 21, 2, 463, 672, 100, 1726, 1727, 1728, 1729, 164, 32, 1730, 337, 559, 1731, 345, 1715, 17, 30, 801, 1107, 914, 256, 1216, 515, 329, 323, 362, 48, 1732, 503, 60, 1733, 345, 128, 305, 1734, 64, 270, 659, 31, 513, 1038, 1735, 23, 750, 781, 36, 343, 1292, 85, 32, 1736, 12, 1614, 137, 23, 750, 408, 160, 1737, 345, 1738, 764, 9, 750, 408, 1739, 1252, 227, 3, 750, 31, 1740, 33, 62, 343, 1722, 750, 1741, 691, 72, 53, 208, 304, 237, 1742, 9, 750, 517, 937, 764, 9, 750, 1737, 33, 1743, 1744, 345, 1715, 388, 32, 1745, 697, 48, 1719, 36, 18, 764, 47, 1024, 362, 344, 345, 1746, 152, 620, 337, 32, 1747, 549, 217, 18, 269, 9, 66, 750, 11, 185, 345, 1715, 388, 549, 217, 1748, 42, 851, 728, 3, 1718, 691, 707, 1068, 80, 1749, 9, 229, 11, 1750, 345, 1715, 211, 733, 23, 750, 1751, 345, 237, 48, 1719, 36, 1162, 737, 162, 236, 77, 454, 1743, 1752, 749, 23, 750, 408, 160, 660, 30, 607, 1753, 698, 127, 345, 1715, 439, 256, 1754, 288, 40, 1162, 324, 25, 321, 322, 9, 48, 60, 11, 1755, 482, 508, 509, 337, 1242, 1756, 1757, 1758, 164, 32, 1759, 292, 83, 551, 589, 1726, 1727, 37, 1760, 691, 707, 119, 481, 482, 23, 1761, 291, 34, 1762, 151, 1763, 329, 1764, 454, 851, 324, 236, 30, 968, 932, 208, 578, 879, 1765, 781, 1766, 233, 65, 23, 309, 431, 1767, 1768, 424, 589, 388, 152, 620, 269, 1769, 62, 337, 256, 1770, 1002, 1771, 431, 1772, 514, 100, 1773, 879, 1511, 1774, 182, 132, 709, 208, 578, 1775, 479, 1735, 1776, 709, 311, 703, 36, 1749, 1777, 424, 589, 170, 128, 95, 932, 311, 1778, 1749, 662, 310, 345, 1715, 338, 607, 1779, 47, 672, 1780, 301, 1781, 1782, 1783, 1784, 1785, 664, 337, 256, 886, 1784, 1786, 62, 337, 53, 1781, 1787, 345, 1715, 417, 152, 476, 508, 509, 703, 704, 593, 53, 98, 99, 709, 311, 703, 47, 1788, 1715, 565, 439, 256, 1789, 40, 2, 709, 703, 704, 330, 815, 1790, 708, 511, 450, 100, 324, 25, 208, 304, 388, 1791, 515, 53, 47, 98, 99, 1792, 691, 707, 435, 30, 85, 1744, 1793, 1794, 1795, 324, 25, 160, 23, 1796, 349, 312, 36, 1797, 1798, 1799, 227, 147, 40, 96, 1800, 378, 1801, 1802, 1803, 1804, 9, 1805, 431, 1806, 657, 251, 41, 1146, 940, 709, 550, 551, 241, 431, 717, 1772, 36, 48, 481, 482, 1124, 499, 1807, 241, 1808, 1785, 1809, 36, 686, 1810, 1811, 1812, 1813, 1814, 241, 396, 956, 1815, 476, 508, 509, 320, 119, 976, 338, 1816, 36, 818, 1813, 1817, 295]\n"
     ]
    }
   ],
   "source": [
    "print(doc_id_token_ids_dict[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH6BHXnyucAx"
   },
   "source": [
    "**Tiến hành xây dựng vector  biểu diễn cho tài liệu/văn bản:**\n",
    "*   Mỗi văn bản/tài liệu sẽ được biểu diễn bằng 1 vector.\n",
    "*   Vector biểu diễn văn bản sẽ có số chiều bằng với kích thước của tập từ vựng (vocab_size).\n",
    "*   Tại mỗi cột/chiều (i) của vector sẽ có giá trị 1 - nếu trong văn bản xuất hiện token_id = i và ngược lại sẽ là 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LA5RmuEVvm2T"
   },
   "outputs": [],
   "source": [
    "# Cấu trúc dữ liệu dạng dictionary -> <key: doc_id, value: encoded_vector>\n",
    "doc_id_encoded_vector_dict = {}\n",
    "\n",
    "# Duyệt qua từng tài liệu/văn bản có trong mảng\n",
    "for doc_idx in doc_id_token_ids_dict.keys():\n",
    "  # Khởi tạo một vector có số chiều = vocab_size và các giá trị [0] -> [0, 0, 0, ...]\n",
    "  encoded_vector = np.zeros(vocab_size)\n",
    "\n",
    "  # Danh sách các token_ids xuất hiện trong tài liệu/văn bản\n",
    "  doc_token_ids = doc_id_token_ids_dict[doc_idx]\n",
    "  \n",
    "  # Duyệt qua từng token xuất hiện trong tài liệu/văn bản\n",
    "  for token_id in doc_token_ids:\n",
    "    # Gán vị trí - cột/chiều thứ (i) của vector giá trị 1 - tương đương với vị trí xuất hiện của token\n",
    "    encoded_vector[token_id] = 1\n",
    "  doc_id_encoded_vector_dict[doc_idx] = encoded_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaYpNnmpxXiG"
   },
   "source": [
    "**Xuất ra màn hình vector  biểu diễn văn bản thứ [10]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmY0yAYyxGpL",
    "outputId": "012c091e-8581-459f-af04-3c3c50111eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Cho phép xuất toàn bộ các giá trị trong encoded_vector của tài liệu\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(doc_id_encoded_vector_dict[10])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
